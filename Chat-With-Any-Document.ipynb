{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TirendazAcademy/LangChain-Tutorials/blob/main/Chat-With-Any-Document.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XaaAFk6QG3Y"
      },
      "source": [
        "# Chat With Anything - From PDFs Files to Image Documents:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKQRUTBYQG3b"
      },
      "source": [
        "### Install the requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RRYSu48huSUW"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip -q install langchain faiss-cpu unstructured\n",
        "pip -q install openai tiktoken\n",
        "pip -q install pytesseract pypdf\n",
        "pip -q install unstructured==0.7.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "id": "sr6ppS0za7TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX3ndyD8E9hN"
      },
      "source": [
        "# Chat & Query your PDF files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhoMomdzQG3c"
      },
      "source": [
        "## Detect Document Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vRy_fppZQG3d"
      },
      "outputs": [],
      "source": [
        "from filetype import guess\n",
        "\n",
        "def detect_document_type(document_path):\n",
        "\n",
        "    guess_file = guess(document_path)\n",
        "    file_type = \"\"\n",
        "    image_types = ['jpg', 'jpeg', 'png', 'gif']\n",
        "\n",
        "    if(guess_file.extension.lower() == \"pdf\"):\n",
        "        file_type = \"pdf\"\n",
        "\n",
        "    elif(guess_file.extension.lower() in image_types):\n",
        "        file_type = \"image\"\n",
        "\n",
        "    else:\n",
        "        file_type = \"unkown\"\n",
        "\n",
        "    return file_type\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwfpliJxQG3d",
        "outputId": "bdf7e6f3-1397-4ecc-8fae-b03552fdf05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Research Paper Type: pdf\n",
            "Article Information Document Type: image\n"
          ]
        }
      ],
      "source": [
        "research_paper_path = \"/content/transformer_paper.pdf\"\n",
        "article_information_path = \"/content/rticle_information.png\"\n",
        "\n",
        "print(f\"Research Paper Type: {detect_document_type(research_paper_path)}\")\n",
        "print(f\"Article Information Document Type: {detect_document_type(article_information_path)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LGFFT0hQG3e"
      },
      "source": [
        "## Extract Documents Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t9_3mkbBQG3f"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders.image import UnstructuredImageLoader\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "\"\"\"\n",
        "YOU CAN UNCOMMENT THE CODE BELOW TO UNDERSTAND THE LOGIC OF THE FUNCTIONS\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "\n",
        "    loader = UnstructuredFileLoader(pdf_file)\n",
        "    documents = loader.load()\n",
        "    pdf_pages_content = '\\n'.join(doc.page_content for doc in documents)\n",
        "\n",
        "    return pdf_pages_content\n",
        "\n",
        "def extract_text_from_image(image_file):\n",
        "\n",
        "    loader = UnstructuredImageLoader(image_file)\n",
        "    documents = loader.load()\n",
        "\n",
        "    image_content = '\\n'.join(doc.page_content for doc in documents)\n",
        "\n",
        "    return image_content\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def extract_file_content(file_path):\n",
        "\n",
        "    file_type = detect_document_type(file_path)\n",
        "\n",
        "    if(file_type == \"pdf\"):\n",
        "        loader = UnstructuredFileLoader(file_path)\n",
        "\n",
        "    elif(file_type == \"image\"):\n",
        "        loader = UnstructuredImageLoader(file_path)\n",
        "\n",
        "    documents = loader.load()\n",
        "    documents_content = '\\n'.join(doc.page_content for doc in documents)\n",
        "\n",
        "    return documents_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FydMC-fXQG3f"
      },
      "outputs": [],
      "source": [
        "#research_paper_content = extract_text_from_pdf(research_paper_path)\n",
        "#article_information_content = extract_text_from_image(article_information_path)\n",
        "\n",
        "\n",
        "research_paper_content = extract_file_content(research_paper_path)\n",
        "article_information_content = extract_file_content(article_information_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9kGWp-hQG3g",
        "outputId": "f56460c3-8146-442d-dbdc-e0c00b14b6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 400 Characters of the Paper: \n",
            "Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works.\n",
            "\n",
            "Attention Is All You Need\n",
            "\n",
            "3 2 0 2\n",
            "\n",
            "Ashish Vaswani∗ Google Brain avaswani@google.com\n",
            "\n",
            "Noam Shazeer∗ Google Brain noam@google.com\n",
            "\n",
            "Niki Parmar∗ Google Research nikip@google.com\n",
            "\n",
            "Jakob Uszkoreit∗ Google Research usz@google.com\n",
            "...\n",
            "---------------\n",
            "First 400 Characters of Article Information Document :\n",
            " Input Files e ‘ File Content in\n",
            "\n",
            "Raw Format\n",
            "\n",
            "Raw Bata Splitter\n",
            "\n",
            "PDF,\n",
            "\n",
            "File Tyee Detector File Content Extractor DifRerent Chunks of the Raw Data\n",
            "\n",
            "°\n",
            "\n",
            "<< }/ oO <\n",
            "\n",
            "© 6 6\n",
            "\n",
            "Chunk\n",
            "\n",
            "Vector Index Transformer\n",
            "\n",
            "Chunks, Embedlelings\n",
            "\n",
            "t\n",
            "\n",
            "See]\n",
            "\n",
            "Response\n",
            "\n",
            "‘ =] Q — Author: Zoumana Keita User...\n"
          ]
        }
      ],
      "source": [
        "nb_characters = 400\n",
        "\n",
        "print(f\"First {nb_characters} Characters of the Paper: \\n{research_paper_content[:nb_characters]}...\")\n",
        "print(\"---\"*5)\n",
        "print(f\"First {nb_characters} Characters of Article Information Document :\\n {article_information_content[:nb_characters]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovyvwo4VQG3g"
      },
      "source": [
        "## Chat Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjjVV0RnQG3h"
      },
      "source": [
        "### Create Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-Brvp2ACQG3h"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkzN5YJ-QG3i",
        "outputId": "c81b34c7-12d0-40dc-c388-28659989c4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1140, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Chunks in Research Paper: 51\n",
            "# Chunks in Article Document: 1\n"
          ]
        }
      ],
      "source": [
        "research_paper_chunks = text_splitter.split_text(research_paper_content)\n",
        "article_information_chunks = text_splitter.split_text(article_information_content)\n",
        "\n",
        "print(f\"# Chunks in Research Paper: {len(research_paper_chunks)}\")\n",
        "print(f\"# Chunks in Article Document: {len(article_information_chunks)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0fTb1OXQG3i"
      },
      "source": [
        "### Create Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2j_TWA_xQG3i"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ16VESDQG3i"
      },
      "source": [
        "### Create Vector Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YhGwAt_GQG3j"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def get_doc_search(text_splitter):\n",
        "\n",
        "    return FAISS.from_texts(text_splitter, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeYNtWtoQG3j",
        "outputId": "323bf4ca-ca28-45dd-efeb-5eea12620d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langchain.vectorstores.faiss.FAISS object at 0x7cee3a515720>\n"
          ]
        }
      ],
      "source": [
        "doc_search_paper = get_doc_search(research_paper_chunks)\n",
        "print(doc_search_paper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCAYKPq2QG3j"
      },
      "source": [
        "### Start chatting with your document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "chain = load_qa_chain(OpenAI(), chain_type = \"map_rerank\",\n",
        "                      return_intermediate_steps=True)\n",
        "\n",
        "def chat_with_file(file_path, query):\n",
        "\n",
        "    file_content = extract_file_content(file_path)\n",
        "    file_splitter = text_splitter.split_text(file_content)\n",
        "\n",
        "    document_search = get_doc_search(file_splitter)\n",
        "    documents = document_search.similarity_search(query)\n",
        "\n",
        "    results = chain({\n",
        "                        \"input_documents\":documents,\n",
        "                        \"question\": query\n",
        "                    },\n",
        "                    return_only_outputs=True)\n",
        "    results = results['intermediate_steps'][0]\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av7cFJ8PQG3k"
      },
      "source": [
        "##### Chat with the image file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvVMW_0DQG3k",
        "outputId": "54cdcb47-bb8a-4695-d476-448eebc6e36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:303: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  This document is about the process of extracting information from raw data, including splitting the data into chunks, detecting the type of file, extracting the content, and creating a vector index and embeddings.\n",
            "\n",
            "Confidence Score: 100\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the document about\"\n",
        "\n",
        "results = chat_with_file(article_information_path, query)\n",
        "\n",
        "answer = results[\"answer\"]\n",
        "confidence_score = results[\"score\"]\n",
        "\n",
        "print(f\"Answer: {answer}\\n\\nConfidence Score: {confidence_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9edAr_8eQG3k"
      },
      "source": [
        "##### Chat with the PDF file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k64BYyeQG3l",
        "outputId": "5d31a95a-7c1a-4c57-9857-52634f6b53fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1140, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  Self-attention is used to compute a representation of the sequence, allowing for the construction of the Transformer which relies entirely on self-attention to compute representations of its input and output without using sequence-aligned RNNs or convolution.\n",
            "\n",
            "Confidence Score: 100\n"
          ]
        }
      ],
      "source": [
        "query = \"Why is the self-attention approach used in this document?\"\n",
        "\n",
        "results = chat_with_file(research_paper_path, query)\n",
        "\n",
        "answer = results[\"answer\"]\n",
        "confidence_score = results[\"score\"]\n",
        "\n",
        "print(f\"Answer: {answer}\\n\\nConfidence Score: {confidence_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi_kh1faQG3l"
      },
      "source": [
        "# Resources\n",
        "\n",
        "- [How to Chat With Any PDFs and Image Files Using Large Language Models — With Code](https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "pandas_benchmark",
      "language": "python",
      "name": "pandas_benchmark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}